{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bff2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# from langchain_postgres import PGVector\n",
    "# from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9e6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Common data processing\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87282f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e58a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "583fda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "connection_string = \"postgresql+psycopg://bsituser:M4pbcMDsbm30zDV6@awseb-e-mmtzduxdgy-stack-awsebrdsdatabase-a1ggrejgeign.cp5mioiwgdbp.ca-central-1.rds.amazonaws.com:5432/vector_db\"\n",
    "\n",
    "engine = create_engine(connection_string, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ac3d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-24 13:32:13,262 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2024-06-24 13:32:13,262 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-06-24 13:32:13,319 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2024-06-24 13:32:13,321 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-06-24 13:32:13,353 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2024-06-24 13:32:13,355 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-06-24 13:32:13,455 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-06-24 13:32:13,457 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s::VARCHAR, %(param_2)s::VARCHAR, %(param_3)s::VARCHAR, %(param_4)s::VARCHAR, %(param_5)s::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s::VARCHAR\n",
      "2024-06-24 13:32:13,458 INFO sqlalchemy.engine.Engine [generated in 0.00326s] {'table_name': 'SELECT document, cmetadata FROM langchain_pg_embedding;', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2024-06-24 13:32:13,491 INFO sqlalchemy.engine.Engine SELECT document, cmetadata FROM langchain_pg_embedding;\n",
      "2024-06-24 13:32:13,494 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-06-24 13:32:15,434 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>document</th>\n",
       "      <th>cmetadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Circulation: Cardiovascular Quality and Outcom...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/36QT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>care were included. Data on study characterist...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/36QT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Key Words:  controlled clinical trials ◼ early...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/36QT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Strong et al Early Termination of Acute Stroke...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/36QT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c. Not mentioned 27 (18.37)\\n(continued on nex...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/8AIM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34063</th>\n",
       "      <td>34063</td>\n",
       "      <td>versus standard consent processes within the E...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/LWYC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34064</th>\n",
       "      <td>34064</td>\n",
       "      <td>114. Godinho A, Schell C, Cunningham JA. How o...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/LWYC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34065</th>\n",
       "      <td>34065</td>\n",
       "      <td>AJ, et al. Perceptions of safety monitoring in...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/LWYC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34066</th>\n",
       "      <td>34066</td>\n",
       "      <td>controlled trial evaluating a digital decision...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/LWYC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34067</th>\n",
       "      <td>34067</td>\n",
       "      <td>preferences for using mobile technologies in c...</td>\n",
       "      <td>{'source': 'C:/Users/pouri/Zotero/storage/LWYC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34068 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                           document  \\\n",
       "0          0  Circulation: Cardiovascular Quality and Outcom...   \n",
       "1          1  care were included. Data on study characterist...   \n",
       "2          2  Key Words:  controlled clinical trials ◼ early...   \n",
       "3          3  Strong et al Early Termination of Acute Stroke...   \n",
       "4          4  c. Not mentioned 27 (18.37)\\n(continued on nex...   \n",
       "...      ...                                                ...   \n",
       "34063  34063  versus standard consent processes within the E...   \n",
       "34064  34064  114. Godinho A, Schell C, Cunningham JA. How o...   \n",
       "34065  34065  AJ, et al. Perceptions of safety monitoring in...   \n",
       "34066  34066  controlled trial evaluating a digital decision...   \n",
       "34067  34067  preferences for using mobile technologies in c...   \n",
       "\n",
       "                                               cmetadata  \n",
       "0      {'source': 'C:/Users/pouri/Zotero/storage/36QT...  \n",
       "1      {'source': 'C:/Users/pouri/Zotero/storage/36QT...  \n",
       "2      {'source': 'C:/Users/pouri/Zotero/storage/36QT...  \n",
       "3      {'source': 'C:/Users/pouri/Zotero/storage/36QT...  \n",
       "4      {'source': 'C:/Users/pouri/Zotero/storage/8AIM...  \n",
       "...                                                  ...  \n",
       "34063  {'source': 'C:/Users/pouri/Zotero/storage/LWYC...  \n",
       "34064  {'source': 'C:/Users/pouri/Zotero/storage/LWYC...  \n",
       "34065  {'source': 'C:/Users/pouri/Zotero/storage/LWYC...  \n",
       "34066  {'source': 'C:/Users/pouri/Zotero/storage/LWYC...  \n",
       "34067  {'source': 'C:/Users/pouri/Zotero/storage/LWYC...  \n",
       "\n",
       "[34068 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"SELECT document, cmetadata FROM langchain_pg_embedding;\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0e53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_metadata = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    d = row['cmetadata']\n",
    "    d['date_added'] = d.pop('Date Added')\n",
    "    d['publication_year'] = d.pop('Publication Year')\n",
    "    d['text'] = row['document']\n",
    "    d['index'] = row['index']\n",
    "    chunks_with_metadata.append(d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd33d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'C:/Users/pouri/Zotero/storage/36QTIN44/Strong et al. - 2021 - Early Termination of Acute Stroke Randomized Contr.pdf',\n",
       " 'page': 0,\n",
       " 'Author': 'Strong, Brent; Oostema, J. Adam; Nikroo, Nadia; Hussain, Murtaza; Reeves, Mathew J.',\n",
       " 'Title': 'Early Termination of Acute Stroke Randomized Controlled Trials Published Between 2013 and 2020: A Systematic Review.',\n",
       " 'date_added': 2023,\n",
       " 'publication_year': 2021,\n",
       " 'text': 'Circulation: Cardiovascular Quality and Outcomes1270\\nCirculation: Cardiovascular Quality and Outcomes is available at http://www.ahajournals.org/journal/circoutcomes Circ Cardiovasc Qual Outcomes. 2021;14:e007995. DOI: 10.1161/CIRCOUTCOMES.121.007995 December 2021 \\nCorrespondence to: Mathew J. Reeves, PhD, Department of Epidemiology and Biostatistics, Michigan State University, B601 W Fee Hall, East Lansing, MI 48824. \\nEmail reevesm@msu.edu\\nSupplemental material is available at https://www.ahajournals.org/doi/suppl/10.1161/CIRCOUTCOMES.121.007995.\\nFor Sources of Funding and Disclosures, see page 1278.\\n© 2021 American Heart Association, Inc.ORIGINAL ARTICLE\\nEarly Termination of Acute Stroke Randomized \\nControlled Trials Published Between 2013 and \\n2020: A Systematic Review\\nBrent Strong , BS; J. Adam Oostema, MD; Nadia Nikroo , BS; Murtaza Hussain , MD; Mathew J. Reeves , PhD\\nBACKGROUND:  Termination of a clinical trial before the maximum planned sample size is accrued can occur for multiple valid \\nreasons but has implications for the interpretation of results. We undertook a systematic review of contemporary acute stroke \\ntrials to document the prevalence of and reasons for early termination.\\nMETHODS:  We searched MEDLINE for randomized controlled trials of acute stroke therapies published between 2013 and \\n2020 in 9 major clinical journals. Manuscripts describing the primary results of phase 2 and phase 3 trials of acute stroke',\n",
       " 'index': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_with_metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99acc28a",
   "metadata": {},
   "source": [
    "# Create graph nodes using text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f328e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_chunk_node_query = \"\"\"\n",
    "# MERGE(mergedChunk:Chunk {chunkId: $chunkParam.index})\n",
    "#     ON CREATE SET \n",
    "#         mergedChunk.authors = $chunkParam.Author,\n",
    "#         mergedChunk.title = $chunkParam.Title,\n",
    "#         mergedChunk.date_added = $chunkParam.date_added, \n",
    "#         mergedChunk.publication_year = $chunkParam.publication_year, \n",
    "#         mergedChunk.page = $chunkParam.page,\n",
    "#         mergedChunk.text = $chunkParam.text\n",
    "# RETURN mergedChunk\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132df95d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot resolve address 3a87071e.databases.neo4j.io:7687",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_util.py:114\u001b[0m, in \u001b[0;36mNetworkUtil._dns_resolver\u001b[1;34m(address, family)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m     info \u001b[38;5;241m=\u001b[39m NetworkUtil\u001b[38;5;241m.\u001b[39mget_address_info(\n\u001b[0;32m    115\u001b[0m         address\u001b[38;5;241m.\u001b[39mhost, address\u001b[38;5;241m.\u001b[39mport, family\u001b[38;5;241m=\u001b[39mfamily,\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39msocket\u001b[38;5;241m.\u001b[39mSOCK_STREAM\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_util.py:102\u001b[0m, in \u001b[0;36mNetworkUtil.get_address_info\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_address_info\u001b[39m(host, port, \u001b[38;5;241m*\u001b[39m, family\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, proto\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\socket.py:963\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    962\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    964\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m kg \u001b[38;5;241m=\u001b[39m Neo4jGraph(\n\u001b[0;32m      2\u001b[0m     url\u001b[38;5;241m=\u001b[39mNEO4J_URI, username\u001b[38;5;241m=\u001b[39mNEO4J_USERNAME, password\u001b[38;5;241m=\u001b[39mNEO4J_PASSWORD, database\u001b[38;5;241m=\u001b[39mNEO4J_DATABASE\n\u001b[0;32m      3\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:350\u001b[0m, in \u001b[0;36mNeo4jGraph.__init__\u001b[1;34m(self, url, username, password, database, timeout, sanitize, refresh_schema, driver_config, enhanced_schema)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# Verify connection\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_driver\u001b[38;5;241m.\u001b[39mverify_connectivity()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mServiceUnavailable:\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect to Neo4j database. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure that the url is correct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1007\u001b[0m, in \u001b[0;36mDriver.verify_connectivity\u001b[1;34m(self, **config)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     experimental_warn(\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll configuration key-word arguments to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify_connectivity() are experimental. They might be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchanged or removed in any future version without prior \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1004\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotice.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[0;32m   1006\u001b[0m session_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_session_config(config)\n\u001b[1;32m-> 1007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_info(session_config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\driver.py:1218\u001b[0m, in \u001b[0;36mDriver._get_server_info\u001b[1;34m(self, session_config)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_server_info\u001b[39m(\u001b[38;5;28mself\u001b[39m, session_config) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ServerInfo:\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session(session_config) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m-> 1218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_get_server_info()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:172\u001b[0m, in \u001b[0;36mSession._get_server_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_server_info\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(READ_ACCESS, liveness_check_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    173\u001b[0m     server_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mserver_info\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:130\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     access_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_connect(\n\u001b[0;32m    131\u001b[0m         access_mode, auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mauth, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39macquire_kwargs\n\u001b[0;32m    132\u001b[0m     )\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_cancellation(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_connect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:161\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, auth, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;66;03m# This is the first time we open a connection to a server in a\u001b[39;00m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;66;03m# cluster environment for this session without explicitly\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;66;03m# we shall use this database explicitly for all subsequent\u001b[39;00m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# actions within this session.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <WORKSPACE> resolve home database\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mupdate_routing_table(\n\u001b[0;32m    162\u001b[0m             database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    163\u001b[0m             imp_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mimpersonated_user,\n\u001b[0;32m    164\u001b[0m             bookmarks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bookmarks(),\n\u001b[0;32m    165\u001b[0m             auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    166\u001b[0m             acquisition_timeout\u001b[38;5;241m=\u001b[39macquisition_timeout,\n\u001b[0;32m    167\u001b[0m             database_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_cached_database\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m acquire_kwargs_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: access_mode,\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliveness_check_timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    176\u001b[0m }\n\u001b[0;32m    177\u001b[0m acquire_kwargs_\u001b[38;5;241m.\u001b[39mupdate(acquire_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:776\u001b[0m, in \u001b[0;36mNeo4jPool.update_routing_table\u001b[1;34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback)\u001b[0m\n\u001b[0;32m    771\u001b[0m prefer_initial_routing_address \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrouting_tables[database]\u001b[38;5;241m.\u001b[39minitialized_without_writers\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefer_initial_routing_address:\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;66;03m# TODO: Test this state\u001b[39;00m\n\u001b[1;32m--> 776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_routing_table_from(\n\u001b[0;32m    777\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress, database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[0;32m    778\u001b[0m         imp_user\u001b[38;5;241m=\u001b[39mimp_user, bookmarks\u001b[38;5;241m=\u001b[39mbookmarks, auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    779\u001b[0m         acquisition_timeout\u001b[38;5;241m=\u001b[39macquisition_timeout,\n\u001b[0;32m    780\u001b[0m         database_callback\u001b[38;5;241m=\u001b[39mdatabase_callback\n\u001b[0;32m    781\u001b[0m     ):\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;66;03m# Why is only the first initial routing address used?\u001b[39;00m\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_routing_table_from(\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;241m*\u001b[39m(existing_routers \u001b[38;5;241m-\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress}), database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[0;32m    786\u001b[0m     imp_user\u001b[38;5;241m=\u001b[39mimp_user, bookmarks\u001b[38;5;241m=\u001b[39mbookmarks, auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    787\u001b[0m     acquisition_timeout\u001b[38;5;241m=\u001b[39macquisition_timeout,\n\u001b[0;32m    788\u001b[0m     database_callback\u001b[38;5;241m=\u001b[39mdatabase_callback\n\u001b[0;32m    789\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:719\u001b[0m, in \u001b[0;36mNeo4jPool._update_routing_table_from\u001b[1;34m(self, database, imp_user, bookmarks, auth, acquisition_timeout, database_callback, *routers)\u001b[0m\n\u001b[0;32m    716\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <POOL> attempting to update routing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    717\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mrepr\u001b[39m, routers))))\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m router \u001b[38;5;129;01min\u001b[39;00m routers:\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m address \u001b[38;5;129;01min\u001b[39;00m NetworkUtil\u001b[38;5;241m.\u001b[39mresolve_address(\n\u001b[0;32m    720\u001b[0m         router, resolver\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_config\u001b[38;5;241m.\u001b[39mresolver\n\u001b[0;32m    721\u001b[0m     ):\n\u001b[0;32m    722\u001b[0m         new_routing_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_routing_table(\n\u001b[0;32m    723\u001b[0m             address\u001b[38;5;241m=\u001b[39maddress, acquisition_timeout\u001b[38;5;241m=\u001b[39macquisition_timeout,\n\u001b[0;32m    724\u001b[0m             database\u001b[38;5;241m=\u001b[39mdatabase, imp_user\u001b[38;5;241m=\u001b[39mimp_user, bookmarks\u001b[38;5;241m=\u001b[39mbookmarks,\n\u001b[0;32m    725\u001b[0m             auth\u001b[38;5;241m=\u001b[39mauth\n\u001b[0;32m    726\u001b[0m         )\n\u001b[0;32m    727\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_routing_table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_util.py:157\u001b[0m, in \u001b[0;36mNetworkUtil.resolve_address\u001b[1;34m(address, family, resolver)\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m resolved_address\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m resolved_address \u001b[38;5;129;01min\u001b[39;00m NetworkUtil\u001b[38;5;241m.\u001b[39m_dns_resolver(\n\u001b[0;32m    158\u001b[0m         address, family\u001b[38;5;241m=\u001b[39mfamily\n\u001b[0;32m    159\u001b[0m     ):\n\u001b[0;32m    160\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[#0000]  _: <RESOLVE> dns resolver out: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    161\u001b[0m                   resolved_address)\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m resolved_address\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\langchain_env\\Lib\\site-packages\\neo4j\\_async_compat\\network\\_util.py:119\u001b[0m, in \u001b[0;36mNetworkUtil._dns_resolver\u001b[1;34m(address, family)\u001b[0m\n\u001b[0;32m    114\u001b[0m     info \u001b[38;5;241m=\u001b[39m NetworkUtil\u001b[38;5;241m.\u001b[39mget_address_info(\n\u001b[0;32m    115\u001b[0m         address\u001b[38;5;241m.\u001b[39mhost, address\u001b[38;5;241m.\u001b[39mport, family\u001b[38;5;241m=\u001b[39mfamily,\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39msocket\u001b[38;5;241m.\u001b[39mSOCK_STREAM\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot resolve address \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(address))\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _resolved_addresses_from_info(info, address\u001b[38;5;241m.\u001b[39m_host_name)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot resolve address 3a87071e.databases.neo4j.io:7687"
     ]
    }
   ],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e12a6151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mergedChunk': {'date_added': 2023,\n",
       "   'publication_year': 2021,\n",
       "   'text': 'Circulation: Cardiovascular Quality and Outcomes1270\\nCirculation: Cardiovascular Quality and Outcomes is available at http://www.ahajournals.org/journal/circoutcomes Circ Cardiovasc Qual Outcomes. 2021;14:e007995. DOI: 10.1161/CIRCOUTCOMES.121.007995 December 2021 \\nCorrespondence to: Mathew J. Reeves, PhD, Department of Epidemiology and Biostatistics, Michigan State University, B601 W Fee Hall, East Lansing, MI 48824. \\nEmail reevesm@msu.edu\\nSupplemental material is available at https://www.ahajournals.org/doi/suppl/10.1161/CIRCOUTCOMES.121.007995.\\nFor Sources of Funding and Disclosures, see page 1278.\\n© 2021 American Heart Association, Inc.ORIGINAL ARTICLE\\nEarly Termination of Acute Stroke Randomized \\nControlled Trials Published Between 2013 and \\n2020: A Systematic Review\\nBrent Strong , BS; J. Adam Oostema, MD; Nadia Nikroo , BS; Murtaza Hussain , MD; Mathew J. Reeves , PhD\\nBACKGROUND:  Termination of a clinical trial before the maximum planned sample size is accrued can occur for multiple valid \\nreasons but has implications for the interpretation of results. We undertook a systematic review of contemporary acute stroke \\ntrials to document the prevalence of and reasons for early termination.\\nMETHODS:  We searched MEDLINE for randomized controlled trials of acute stroke therapies published between 2013 and \\n2020 in 9 major clinical journals. Manuscripts describing the primary results of phase 2 and phase 3 trials of acute stroke',\n",
       "   'page': 0,\n",
       "   'title': 'Early Termination of Acute Stroke Randomized Controlled Trials Published Between 2013 and 2020: A Systematic Review.',\n",
       "   'chunkId': 0,\n",
       "   'authors': 'Strong, Brent; Oostema, J. Adam; Nikroo, Nadia; Hussain, Murtaza; Reeves, Mathew J.'}}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kg.query(merge_chunk_node_query, \n",
    "#          params={'chunkParam':chunks_with_metadata[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e09a9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kg.query(\"\"\"\n",
    "# CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "#     FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6b63790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"DROP INDEX form_10k_chunks;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9696bc5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 2,\n",
       "  'name': 'constraint_42a79aaf',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'RANGE',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Movie'],\n",
       "  'properties': ['title'],\n",
       "  'indexProvider': 'range-1.0',\n",
       "  'owningConstraint': 'constraint_42a79aaf',\n",
       "  'lastRead': neo4j.time.DateTime(2024, 6, 14, 14, 58, 11, 233000000, tzinfo=<UTC>),\n",
       "  'readCount': 3},\n",
       " {'id': 4,\n",
       "  'name': 'constraint_a831e4ce',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'RANGE',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Person'],\n",
       "  'properties': ['name'],\n",
       "  'indexProvider': 'range-1.0',\n",
       "  'owningConstraint': 'constraint_a831e4ce',\n",
       "  'lastRead': neo4j.time.DateTime(2024, 6, 14, 14, 58, 31, 47000000, tzinfo=<UTC>),\n",
       "  'readCount': 3},\n",
       " {'id': 0,\n",
       "  'name': 'index_343aff4e',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'LOOKUP',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': None,\n",
       "  'properties': None,\n",
       "  'indexProvider': 'token-lookup-1.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2024, 6, 21, 23, 41, 14, 75000000, tzinfo=<UTC>),\n",
       "  'readCount': 114},\n",
       " {'id': 6,\n",
       "  'name': 'index_d6613655',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'RANGE',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Movie'],\n",
       "  'properties': ['released'],\n",
       "  'indexProvider': 'range-1.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2024, 6, 14, 14, 58, 20, 225000000, tzinfo=<UTC>),\n",
       "  'readCount': 1},\n",
       " {'id': 1,\n",
       "  'name': 'index_f7700477',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'LOOKUP',\n",
       "  'entityType': 'RELATIONSHIP',\n",
       "  'labelsOrTypes': None,\n",
       "  'properties': None,\n",
       "  'indexProvider': 'token-lookup-1.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': None,\n",
       "  'readCount': 0},\n",
       " {'id': 7,\n",
       "  'name': 'movie_tagline_embeddings',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'VECTOR',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Movie'],\n",
       "  'properties': ['taglineEmbedding'],\n",
       "  'indexProvider': 'vector-2.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2024, 6, 14, 15, 50, 53, 24000000, tzinfo=<UTC>),\n",
       "  'readCount': 2},\n",
       " {'id': 10,\n",
       "  'name': 'paper_chunks_vec',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'VECTOR',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Chunk'],\n",
       "  'properties': ['textEmbedding'],\n",
       "  'indexProvider': 'vector-2.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': None,\n",
       "  'readCount': None},\n",
       " {'id': 8,\n",
       "  'name': 'unique_chunk',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'RANGE',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Chunk'],\n",
       "  'properties': ['chunkId'],\n",
       "  'indexProvider': 'range-1.0',\n",
       "  'owningConstraint': 'unique_chunk',\n",
       "  'lastRead': neo4j.time.DateTime(2024, 6, 22, 0, 5, 37, 598000000, tzinfo=<UTC>),\n",
       "  'readCount': 102540}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f100dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 34068/34068 [21:32<00:00, 26.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 34068 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# node_count = 0\n",
    "# for chunk in tqdm(chunks_with_metadata):\n",
    "# #     print(f\"Creating `:Chunk` node for chunk ID {chunk['index']}\")\n",
    "#     kg.query(merge_chunk_node_query, \n",
    "#             params={\n",
    "#                 'chunkParam': chunk\n",
    "#             })\n",
    "#     node_count += 1\n",
    "# print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b32325be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nodeCount': 34068}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (n)\n",
    "         RETURN count(n) as nodeCount\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3e8c6",
   "metadata": {},
   "source": [
    "# Create a vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5c1e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kg.query(\"\"\"\n",
    "#          CREATE VECTOR INDEX `paper_chunks_vec` IF NOT EXISTS\n",
    "#           FOR (c:Chunk) ON (c.textEmbedding) \n",
    "#           OPTIONS { indexConfig: {\n",
    "#             `vector.dimensions`: 1536,\n",
    "#             `vector.similarity_function`: 'cosine'    \n",
    "#          }}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c357a6c",
   "metadata": {},
   "source": [
    "# Calculate embedding vectors for chunks and populate index\n",
    "- This query calculates the embedding vector and stores it as a property called `textEmbedding` on each `Chunk` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d648c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks to process: 34068\n"
     ]
    }
   ],
   "source": [
    "result = kg.query(\"MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL RETURN count(chunk) AS total\")\n",
    "total_chunks = result[0][\"total\"]\n",
    "print(f\"Total chunks to process: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9429955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch up to offset 100\n",
      "Processed batch up to offset 200\n",
      "Processed batch up to offset 300\n",
      "Processed batch up to offset 400\n",
      "Processed batch up to offset 500\n",
      "Processed batch up to offset 600\n",
      "Processed batch up to offset 700\n",
      "Processed batch up to offset 800\n",
      "Processed batch up to offset 900\n",
      "Processed batch up to offset 1000\n",
      "Processed batch up to offset 1100\n",
      "Processed batch up to offset 1200\n",
      "Processed batch up to offset 1300\n",
      "Processed batch up to offset 1400\n",
      "Processed batch up to offset 1500\n",
      "Processed batch up to offset 1600\n",
      "Processed batch up to offset 1700\n",
      "Processed batch up to offset 1800\n",
      "Processed batch up to offset 1900\n",
      "Processed batch up to offset 2000\n",
      "Processed batch up to offset 2100\n",
      "Processed batch up to offset 2200\n",
      "Processed batch up to offset 2300\n",
      "Processed batch up to offset 2400\n",
      "Processed batch up to offset 2500\n",
      "Processed batch up to offset 2600\n",
      "Processed batch up to offset 2700\n",
      "Processed batch up to offset 2800\n",
      "Processed batch up to offset 2900\n",
      "Processed batch up to offset 3000\n",
      "Processed batch up to offset 3100\n",
      "Processed batch up to offset 3200\n",
      "Processed batch up to offset 3300\n",
      "Processed batch up to offset 3400\n",
      "Processed batch up to offset 3500\n",
      "Processed batch up to offset 3600\n",
      "Processed batch up to offset 3700\n",
      "Processed batch up to offset 3800\n",
      "Processed batch up to offset 3900\n",
      "Processed batch up to offset 4000\n",
      "Processed batch up to offset 4100\n",
      "Processed batch up to offset 4200\n",
      "Processed batch up to offset 4300\n",
      "Processed batch up to offset 4400\n",
      "Processed batch up to offset 4500\n",
      "Processed batch up to offset 4600\n",
      "Processed batch up to offset 4700\n",
      "Processed batch up to offset 4800\n",
      "Processed batch up to offset 4900\n",
      "Processed batch up to offset 5000\n",
      "Processed batch up to offset 5100\n",
      "Processed batch up to offset 5200\n",
      "Processed batch up to offset 5300\n",
      "Processed batch up to offset 5400\n",
      "Processed batch up to offset 5500\n",
      "Processed batch up to offset 5600\n",
      "Processed batch up to offset 5700\n",
      "Processed batch up to offset 5800\n",
      "Processed batch up to offset 5900\n",
      "Processed batch up to offset 6000\n",
      "Processed batch up to offset 6100\n",
      "Processed batch up to offset 6200\n",
      "Processed batch up to offset 6300\n",
      "Processed batch up to offset 6400\n",
      "Processed batch up to offset 6500\n",
      "Processed batch up to offset 6600\n",
      "Processed batch up to offset 6700\n",
      "Processed batch up to offset 6800\n",
      "Processed batch up to offset 6900\n",
      "Processed batch up to offset 7000\n",
      "Processed batch up to offset 7100\n",
      "Processed batch up to offset 7200\n",
      "Processed batch up to offset 7300\n",
      "Processed batch up to offset 7400\n",
      "Processed batch up to offset 7500\n",
      "Processed batch up to offset 7600\n",
      "Processed batch up to offset 7700\n",
      "Processed batch up to offset 7800\n",
      "Processed batch up to offset 7900\n",
      "Processed batch up to offset 8000\n",
      "Processed batch up to offset 8100\n",
      "Processed batch up to offset 8200\n",
      "Processed batch up to offset 8300\n",
      "Processed batch up to offset 8400\n",
      "Processed batch up to offset 8500\n",
      "Processed batch up to offset 8600\n",
      "Processed batch up to offset 8700\n",
      "Processed batch up to offset 8800\n",
      "Processed batch up to offset 8900\n",
      "Processed batch up to offset 9000\n",
      "Processed batch up to offset 9100\n",
      "Processed batch up to offset 9200\n",
      "Processed batch up to offset 9300\n",
      "Processed batch up to offset 9400\n",
      "Processed batch up to offset 9500\n",
      "Processed batch up to offset 9600\n",
      "Processed batch up to offset 9700\n",
      "Processed batch up to offset 9800\n",
      "Processed batch up to offset 9900\n",
      "Processed batch up to offset 10000\n",
      "Processed batch up to offset 10100\n",
      "Processed batch up to offset 10200\n",
      "Processed batch up to offset 10300\n",
      "Processed batch up to offset 10400\n",
      "Processed batch up to offset 10500\n",
      "Processed batch up to offset 10600\n",
      "Processed batch up to offset 10700\n",
      "Processed batch up to offset 10800\n",
      "Processed batch up to offset 10900\n",
      "Processed batch up to offset 11000\n",
      "Processed batch up to offset 11100\n",
      "Processed batch up to offset 11200\n",
      "Processed batch up to offset 11300\n",
      "Processed batch up to offset 11400\n",
      "Processed batch up to offset 11500\n",
      "Processed batch up to offset 11600\n",
      "Processed batch up to offset 11700\n",
      "Processed batch up to offset 11800\n",
      "Processed batch up to offset 11900\n",
      "Processed batch up to offset 12000\n",
      "Processed batch up to offset 12100\n",
      "Processed batch up to offset 12200\n",
      "Processed batch up to offset 12300\n",
      "Processed batch up to offset 12400\n",
      "Processed batch up to offset 12500\n",
      "Processed batch up to offset 12600\n",
      "Processed batch up to offset 12700\n",
      "Processed batch up to offset 12800\n",
      "Processed batch up to offset 12900\n",
      "Processed batch up to offset 13000\n",
      "Processed batch up to offset 13100\n",
      "Processed batch up to offset 13200\n",
      "Processed batch up to offset 13300\n",
      "Processed batch up to offset 13400\n",
      "Processed batch up to offset 13500\n",
      "Processed batch up to offset 13600\n",
      "Processed batch up to offset 13700\n",
      "Processed batch up to offset 13800\n",
      "Processed batch up to offset 13900\n",
      "Processed batch up to offset 14000\n",
      "Processed batch up to offset 14100\n",
      "Processed batch up to offset 14200\n",
      "Processed batch up to offset 14300\n",
      "Processed batch up to offset 14400\n",
      "Processed batch up to offset 14500\n",
      "Processed batch up to offset 14600\n",
      "Processed batch up to offset 14700\n",
      "Processed batch up to offset 14800\n",
      "Processed batch up to offset 14900\n",
      "Processed batch up to offset 15000\n",
      "Processed batch up to offset 15100\n",
      "Processed batch up to offset 15200\n",
      "Processed batch up to offset 15300\n",
      "Processed batch up to offset 15400\n",
      "Processed batch up to offset 15500\n",
      "Processed batch up to offset 15600\n",
      "Processed batch up to offset 15700\n",
      "Processed batch up to offset 15800\n",
      "Processed batch up to offset 15900\n",
      "Processed batch up to offset 16000\n",
      "Processed batch up to offset 16100\n",
      "Processed batch up to offset 16200\n",
      "Processed batch up to offset 16300\n",
      "Processed batch up to offset 16400\n",
      "Processed batch up to offset 16500\n",
      "Processed batch up to offset 16600\n",
      "Processed batch up to offset 16700\n",
      "Processed batch up to offset 16800\n",
      "Processed batch up to offset 16900\n",
      "Processed batch up to offset 17000\n",
      "Processed batch up to offset 17100\n",
      "Processed batch up to offset 17200\n",
      "Processed batch up to offset 17300\n",
      "Processed batch up to offset 17400\n",
      "Processed batch up to offset 17500\n",
      "Processed batch up to offset 17600\n",
      "Processed batch up to offset 17700\n",
      "Processed batch up to offset 17800\n",
      "Processed batch up to offset 17900\n",
      "Processed batch up to offset 18000\n",
      "Processed batch up to offset 18100\n",
      "Processed batch up to offset 18200\n",
      "Processed batch up to offset 18300\n",
      "Processed batch up to offset 18400\n",
      "Processed batch up to offset 18500\n",
      "Processed batch up to offset 18600\n",
      "Processed batch up to offset 18700\n",
      "Processed batch up to offset 18800\n",
      "Processed batch up to offset 18900\n",
      "Processed batch up to offset 19000\n",
      "Processed batch up to offset 19100\n",
      "Processed batch up to offset 19200\n",
      "Processed batch up to offset 19300\n",
      "Processed batch up to offset 19400\n",
      "Processed batch up to offset 19500\n",
      "Processed batch up to offset 19600\n",
      "Processed batch up to offset 19700\n",
      "Processed batch up to offset 19800\n",
      "Processed batch up to offset 19900\n",
      "Processed batch up to offset 20000\n",
      "Processed batch up to offset 20100\n",
      "Processed batch up to offset 20200\n",
      "Processed batch up to offset 20300\n",
      "Processed batch up to offset 20400\n",
      "Processed batch up to offset 20500\n",
      "Processed batch up to offset 20600\n",
      "Processed batch up to offset 20700\n",
      "Processed batch up to offset 20800\n",
      "Processed batch up to offset 20900\n",
      "Processed batch up to offset 21000\n",
      "Processed batch up to offset 21100\n",
      "Processed batch up to offset 21200\n",
      "Processed batch up to offset 21300\n",
      "Processed batch up to offset 21400\n",
      "Processed batch up to offset 21500\n",
      "Processed batch up to offset 21600\n",
      "Processed batch up to offset 21700\n",
      "Processed batch up to offset 21800\n",
      "Processed batch up to offset 21900\n",
      "Processed batch up to offset 22000\n",
      "Processed batch up to offset 22100\n",
      "Processed batch up to offset 22200\n",
      "Processed batch up to offset 22300\n",
      "Processed batch up to offset 22400\n",
      "Processed batch up to offset 22500\n",
      "Processed batch up to offset 22600\n",
      "Processed batch up to offset 22700\n",
      "Processed batch up to offset 22800\n",
      "Processed batch up to offset 22900\n",
      "Processed batch up to offset 23000\n",
      "Processed batch up to offset 23100\n",
      "Processed batch up to offset 23200\n",
      "Processed batch up to offset 23300\n",
      "Processed batch up to offset 23400\n",
      "Processed batch up to offset 23500\n",
      "Processed batch up to offset 23600\n",
      "Processed batch up to offset 23700\n",
      "Processed batch up to offset 23800\n",
      "Processed batch up to offset 23900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch up to offset 24000\n",
      "Processed batch up to offset 24100\n",
      "Processed batch up to offset 24200\n",
      "Processed batch up to offset 24300\n",
      "Processed batch up to offset 24400\n",
      "Processed batch up to offset 24500\n",
      "Processed batch up to offset 24600\n",
      "Processed batch up to offset 24700\n",
      "Processed batch up to offset 24800\n",
      "Processed batch up to offset 24900\n",
      "Processed batch up to offset 25000\n",
      "Processed batch up to offset 25100\n",
      "Processed batch up to offset 25200\n",
      "Processed batch up to offset 25300\n",
      "Processed batch up to offset 25400\n",
      "Processed batch up to offset 25500\n",
      "Processed batch up to offset 25600\n",
      "Processed batch up to offset 25700\n",
      "Processed batch up to offset 25800\n",
      "Processed batch up to offset 25900\n",
      "Processed batch up to offset 26000\n",
      "Processed batch up to offset 26100\n",
      "Processed batch up to offset 26200\n",
      "Processed batch up to offset 26300\n",
      "Processed batch up to offset 26400\n",
      "Processed batch up to offset 26500\n",
      "Processed batch up to offset 26600\n",
      "Processed batch up to offset 26700\n",
      "Processed batch up to offset 26800\n",
      "Processed batch up to offset 26900\n",
      "Processed batch up to offset 27000\n",
      "Processed batch up to offset 27100\n",
      "Processed batch up to offset 27200\n",
      "Processed batch up to offset 27300\n",
      "Processed batch up to offset 27400\n",
      "Processed batch up to offset 27500\n",
      "Processed batch up to offset 27600\n",
      "Processed batch up to offset 27700\n",
      "Processed batch up to offset 27800\n",
      "Processed batch up to offset 27900\n",
      "Processed batch up to offset 28000\n",
      "Processed batch up to offset 28100\n",
      "Processed batch up to offset 28200\n",
      "Processed batch up to offset 28300\n",
      "Processed batch up to offset 28400\n",
      "Processed batch up to offset 28500\n",
      "Processed batch up to offset 28600\n",
      "Processed batch up to offset 28700\n",
      "Processed batch up to offset 28800\n",
      "Processed batch up to offset 28900\n",
      "Processed batch up to offset 29000\n",
      "Processed batch up to offset 29100\n",
      "Processed batch up to offset 29200\n",
      "Processed batch up to offset 29300\n",
      "Processed batch up to offset 29400\n",
      "Processed batch up to offset 29500\n",
      "Processed batch up to offset 29600\n",
      "Processed batch up to offset 29700\n",
      "Processed batch up to offset 29800\n",
      "Processed batch up to offset 29900\n",
      "Processed batch up to offset 30000\n",
      "Processed batch up to offset 30100\n",
      "Processed batch up to offset 30200\n",
      "Processed batch up to offset 30300\n",
      "Processed batch up to offset 30400\n",
      "Processed batch up to offset 30500\n",
      "Processed batch up to offset 30600\n",
      "Processed batch up to offset 30700\n",
      "Processed batch up to offset 30800\n",
      "Processed batch up to offset 30900\n",
      "Processed batch up to offset 31000\n",
      "Processed batch up to offset 31100\n",
      "Processed batch up to offset 31200\n",
      "Processed batch up to offset 31300\n",
      "Processed batch up to offset 31400\n",
      "Processed batch up to offset 31500\n",
      "Processed batch up to offset 31600\n",
      "Processed batch up to offset 31700\n",
      "Processed batch up to offset 31800\n",
      "Processed batch up to offset 31900\n",
      "Processed batch up to offset 32000\n",
      "Processed batch up to offset 32100\n",
      "Processed batch up to offset 32200\n",
      "Processed batch up to offset 32300\n",
      "Processed batch up to offset 32400\n",
      "Processed batch up to offset 32500\n",
      "Processed batch up to offset 32600\n",
      "Processed batch up to offset 32700\n",
      "Processed batch up to offset 32800\n",
      "Processed batch up to offset 32900\n",
      "Processed batch up to offset 33000\n",
      "Processed batch up to offset 33100\n",
      "Processed batch up to offset 33200\n",
      "Processed batch up to offset 33300\n",
      "Processed batch up to offset 33400\n",
      "Processed batch up to offset 33500\n",
      "Processed batch up to offset 33600\n",
      "Processed batch up to offset 33700\n",
      "Processed batch up to offset 33800\n",
      "Processed batch up to offset 33900\n",
      "Processed batch up to offset 34000\n",
      "Processed batch up to offset 34100\n",
      "All chunks have been processed.\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 100\n",
    "\n",
    "# offset = 0\n",
    "# while offset < total_chunks:\n",
    "#     query = \"\"\"\n",
    "#     MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "#     WITH chunk SKIP $offset LIMIT $batch_size\n",
    "#     WITH chunk, genai.vector.encode(\n",
    "#       chunk.text, \n",
    "#       \"OpenAI\", \n",
    "#       {\n",
    "#         token: $openAiApiKey\n",
    "#       }) AS vector\n",
    "#     CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "#     \"\"\"\n",
    "#     kg.query(query, params={\"openAiApiKey\": OPENAI_API_KEY, \"offset\": offset, \"batch_size\": batch_size})\n",
    "#     offset += batch_size\n",
    "#     print(f\"Processed batch up to offset {offset}\")\n",
    "\n",
    "# print(\"All chunks have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec529b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#     MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "#     WITH chunk, genai.vector.encode(\n",
    "#       chunk.text, \n",
    "#       \"OpenAI\", \n",
    "#       {\n",
    "#         token: $openAiApiKey\n",
    "#       }) AS vector\n",
    "#     CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "#     \"\"\", \n",
    "#     params={\"openAiApiKey\":OPENAI_API_KEY} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73ac2979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The REFLECT statement: Reporting guidelines for randomized controlled trials in livestock and food safety: Explanation and elaboration'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = list(set([i['Title'] for i in chunks_with_metadata]))\n",
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20f68c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Braend, A. M.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_in_metadata = list(set([i['Author'] for i in chunks_with_metadata]))\n",
    "authors = []\n",
    "for a in authors_in_metadata:\n",
    "    for b in a.split(';'):\n",
    "        authors.append(b.strip())\n",
    "authors = list(set(authors))\n",
    "authors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "248131a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 850/850 [00:56<00:00, 15.10it/s]\n"
     ]
    }
   ],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (c:Chunk)\n",
    "  WHERE c.title = $title\n",
    "  WITH c\n",
    "    ORDER BY c.chunkId ASC\n",
    "  WITH collect(c) as section_chunk_list\n",
    "    CALL apoc.nodes.link(\n",
    "        section_chunk_list, \n",
    "        \"NEXT\", \n",
    "        {avoidDuplicates: true}\n",
    "    )\n",
    "  RETURN size(section_chunk_list)\n",
    "\"\"\"\n",
    "\n",
    "for t in tqdm(titles):\n",
    "    kg.query(cypher, params={'title': t})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41b2e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Chunk {title: STRING, chunkId: INTEGER, text: STRING, textEmbedding: LIST, authors: STRING, date_added: INTEGER, publication_year: INTEGER, page: INTEGER}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Chunk)-[:NEXT]->(:Chunk)\n"
     ]
    }
   ],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e748f080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
